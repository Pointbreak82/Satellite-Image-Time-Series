{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPMnGSb02rHeL7zwg8/7Ebt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pointbreak82/Satellite-Image-Time-Series/blob/main/SITSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_hZTDiPeA60",
        "outputId": "c24df072-aa3a-40a2-f769-00678969b301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Satellite-Image-Time-Series-'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 10 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (10/10), done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Downloading sentinel2-munich480.zip to /content\n",
            "100% 15.5G/15.5G [02:46<00:00, 106MB/s]\n",
            "100% 15.5G/15.5G [02:46<00:00, 100MB/s]\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Pointbreak82/Satellite-Image-Time-Series-.git\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/Satellite-Image-Time-Series-/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d artelabsuper/sentinel2-munich480"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install scikit-image\n",
        "!pip install tqdm\n",
        "!pip install visdom==0.1.8.4\n",
        "!pip3 install torch torchvision"
      ],
      "metadata": {
        "id": "tCQ-K7UY-zqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94dcddb6-2b0a-434a-bbbb-23cb2b98bce6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2023.7.22)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.23.5)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.1)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.8 snuggs-1.4.7\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting visdom==0.1.8.4\n",
            "  Downloading visdom-0.1.8.4.tar.gz (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (1.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (2.31.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (6.3.2)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (23.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (1.16.0)\n",
            "Collecting torchfile (from visdom==0.1.8.4)\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (1.6.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from visdom==0.1.8.4) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.8.4) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.8.4) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.8.4) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visdom==0.1.8.4) (2023.7.22)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.4-py3-none-any.whl size=226637 sha256=a7fac4ffb4680f5a76c6764beb9f32d460e4b35fe123b9395e968b21751b6030\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/06/68/a32a0050c901f9c25fd027b9a5bb97e815157090168a1c89aa\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5692 sha256=77d4c22e8235b3127ee0ae22fdc80317a5737f7e650ff3fdd49b6b7d13c5d1c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/e9/87/1c51daf8e468d5c14931f8ac3344880f903ba96b063675cac2\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: torchfile, visdom\n",
            "Successfully installed torchfile-0.1.0 visdom-0.1.8.4\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for file in os.listdir('/content'):\n",
        "    print(file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkyUc8pS6cRa",
        "outputId": "ced5ee81-13c6-4fd2-df8a-bcc5f29ce93b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".config\n",
            "sentinel2-munich480.zip\n",
            "Satellite-Image-Time-Series-\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Specify the name of the downloaded ZIP file\n",
        "zip_file_name = 'sentinel2-munich480.zip'\n",
        "\n",
        "# Specify the target directory for extraction\n",
        "target_directory = '/content/sentinel2-munich480'\n",
        "\n",
        "# Create the target directory if it doesn't exist\n",
        "os.makedirs(target_directory, exist_ok=True)\n",
        "\n",
        "# Get the total number of files in the ZIP archive for progress tracking\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    total_files = len(zip_ref.infolist())\n",
        "\n",
        "# Extract the contents of the ZIP file with a progress bar\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    for file_info in tqdm(zip_ref.infolist(), desc=\"Extracting\", unit=\" files\", ncols=100):\n",
        "        zip_ref.extract(file_info, target_directory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNNirgAzuXpl",
        "outputId": "8358cd3c-53d7-4351-93c2-223abb5e9cc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting: 100%|███████████████████████████████████| 2298627/2298627 [09:10<00:00, 4178.37 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.ndimage.filters import maximum_filter1d\n",
        "import random\n",
        "import rasterio\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "LABEL_FILENAME = \"y.tif\"\n",
        "\n",
        "def get_dates(path, n=None):\n",
        "    \"\"\"\n",
        "    extracts a list of unique dates from dataset sample\n",
        "\n",
        "    :param path: to dataset sample folder\n",
        "    :param n: choose n random samples from all available dates\n",
        "    :return: list of unique dates in YYYYMMDD format\n",
        "    \"\"\"\n",
        "\n",
        "    files = os.listdir(path)\n",
        "    dates = list()\n",
        "    for f in files:\n",
        "        f = f.split(\"_\")[0]\n",
        "        if len(f) == 8:  # 20160101\n",
        "            dates.append(f)\n",
        "\n",
        "    dates = set(dates)\n",
        "\n",
        "    if n is not None:\n",
        "        dates = random.sample(dates, n)\n",
        "\n",
        "    dates = list(dates)\n",
        "    dates.sort()\n",
        "    return dates\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    # Add other transformations as needed\n",
        "])\n",
        "\n",
        "class SentinelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, seqlength=30, tileids=None,input_channels=13,transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.name = os.path.basename(root_dir)\n",
        "        self.data_dirs = [d for d in os.listdir(self.root_dir) if d.startswith(\"data\")]\n",
        "        self.seqlength = seqlength\n",
        "        self.munich_format = None\n",
        "        self.src_labels = None\n",
        "        self.dst_labels = None\n",
        "        self.unique_labels = np.array([], dtype=float)\n",
        "        self.b8_index = 3  # Munich dataset\n",
        "        self.b4_index = 2  # Munich dataset\n",
        "        self.transform=transform\n",
        "        stats = dict(\n",
        "            rejected_nopath=0,\n",
        "            rejected_length=0,\n",
        "            total_samples=0\n",
        "        )\n",
        "\n",
        "        self.samples = list()\n",
        "        self.ndates = list()\n",
        "\n",
        "        dirs = []\n",
        "        if tileids is None:\n",
        "            for d in self.data_dirs:\n",
        "                dirs_name = os.listdir(os.path.join(self.root_dir, d))\n",
        "                dirs_path = [os.path.join(self.root_dir, d, f) for f in dirs_name]\n",
        "                dirs.extend(dirs_path)\n",
        "        else:\n",
        "            with open(os.path.join(self.root_dir, tileids), 'r') as f:\n",
        "                files = [el.replace(\"\\n\", \"\") for el in f.readlines()]\n",
        "            for d in self.data_dirs:\n",
        "                dirs_path = [os.path.join(self.root_dir, d, f) for f in files]\n",
        "                dirs.extend(dirs_path)\n",
        "\n",
        "        self.classids, self.classes = self.read_classes(os.path.join(self.root_dir, \"classes.txt\"))\n",
        "\n",
        "        for path in dirs:\n",
        "            if not os.path.exists(path):\n",
        "                stats[\"rejected_nopath\"] += 1\n",
        "                continue\n",
        "            if not os.path.exists(os.path.join(path, LABEL_FILENAME)):\n",
        "                stats[\"rejected_nopath\"] += 1\n",
        "                continue\n",
        "\n",
        "            ndates = len(self.get_dates(path))\n",
        "\n",
        "            if ndates < self.seqlength:\n",
        "                stats[\"rejected_length\"] += 1\n",
        "                continue\n",
        "\n",
        "            stats[\"total_samples\"] += 1\n",
        "            self.samples.append(path)\n",
        "            self.ndates.append(ndates)\n",
        "\n",
        "        self.print_stats(stats)\n",
        "\n",
        "    def read_classes(self, csv):\n",
        "        with open(csv, 'r') as f:\n",
        "            classes = f.readlines()\n",
        "\n",
        "        ids = list()\n",
        "        names = list()\n",
        "        for row in classes:\n",
        "            row = row.replace(\"\\n\", \"\")\n",
        "            if '|' in row:\n",
        "                id, cl = row.split('|')\n",
        "                ids.append(int(id))\n",
        "                names.append(cl)\n",
        "\n",
        "        return ids, names\n",
        "\n",
        "    def get_image_h_w(self):\n",
        "        label, profile = self.read(os.path.join(self.samples[0], LABEL_FILENAME))\n",
        "        return label.shape[-2], label.shape[-1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.samples[idx]\n",
        "        if path.endswith(os.sep):\n",
        "            path = path[:-1]\n",
        "        patch_id = os.path.basename(path)\n",
        "\n",
        "        label, profile = self.read(os.path.join(path, LABEL_FILENAME))\n",
        "        profile[\"name\"] = self.samples[idx]\n",
        "\n",
        "        dates = self.get_dates(path, n=self.seqlength)\n",
        "\n",
        "        x10 = []\n",
        "        x20 = []\n",
        "        x60 = []\n",
        "\n",
        "        for date in dates:\n",
        "            if self.munich_format is None:\n",
        "                self.munich_format = os.path.exists(os.path.join(path, date + \"_10m.tif\"))\n",
        "                if self.munich_format:\n",
        "                    self.b8_index = 3\n",
        "                    self.b4_index = 2\n",
        "                else:\n",
        "                    self.b8_index = 6\n",
        "                    self.b4_index = 2\n",
        "            if self.munich_format:\n",
        "                x10.append(self.read(os.path.join(path, date + \"_10m.tif\"))[0])\n",
        "                x20.append(self.read(os.path.join(path, date + \"_20m.tif\"))[0])\n",
        "                x60.append(self.read(os.path.join(path, date + \"_60m.tif\"))[0])\n",
        "            else:\n",
        "                x10.append(self.read(os.path.join(path, date + \".tif\"))[0])\n",
        "\n",
        "        x10 = np.array(x10) * 1e-4\n",
        "        if self.munich_format:\n",
        "            x20 = np.array(x20) * 1e-4\n",
        "            x60 = np.array(x60) * 1e-4\n",
        "\n",
        "        label = label[0]\n",
        "        self.unique_labels = np.unique(np.concatenate([label.flatten(), self.unique_labels]))\n",
        "        new = np.zeros(label.shape, np.int)\n",
        "        for cl, i in zip(self.classids, range(len(self.classids))):\n",
        "            new[label == cl] = i\n",
        "\n",
        "        label = new\n",
        "\n",
        "        label = torch.from_numpy(label)\n",
        "        x10 = torch.from_numpy(x10)\n",
        "        if self.munich_format:\n",
        "            x20 = torch.from_numpy(x20)\n",
        "            x60 = torch.from_numpy(x60)\n",
        "\n",
        "            x20 = F.interpolate(x20, size=x10.shape[2:4])\n",
        "            x60 = F.interpolate(x60, size=x10.shape[2:4])\n",
        "\n",
        "            x = torch.cat((x10, x20, x60), 1)\n",
        "        else:\n",
        "            x = x10\n",
        "\n",
        "        x = x.permute(1, 0, 2, 3)\n",
        "        x = x.float()\n",
        "        label = label.long()\n",
        "\n",
        "        target_ndvi = self.get_all_signatures(x, label, len(self.classids), self.b4_index, self.b8_index)\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            target_ndvi = self.transform(target_ndvi)\n",
        "\n",
        "        return x, label, target_ndvi.float(), dates, patch_id\n",
        "\n",
        "    def read(self, file):\n",
        "        with rasterio.open(file) as src:\n",
        "            return src.read(), src.profile\n",
        "\n",
        "    def get_all_signatures(self, inp, target, num_cls, b4_index, b8_index):\n",
        "        c, t, h, w = inp.shape\n",
        "        output_ndvi = np.zeros((t, h, w), dtype=np.float)\n",
        "\n",
        "        for cls_index_ in range(0, num_cls):\n",
        "            pts = (target == cls_index_).numpy()\n",
        "            all_ndvi_x_cls = []\n",
        "            for row, yr in enumerate(pts):\n",
        "                for col, xc in enumerate(yr):\n",
        "                    if xc:\n",
        "                        b8 = inp[b8_index, :, row, col]\n",
        "                        b4 = inp[b4_index, :, row, col]\n",
        "                        ndvi = (b8 - b4) / (b8 + b4)\n",
        "                        ndvi = np.nan_to_num(ndvi.numpy())\n",
        "                        all_ndvi_x_cls.append(ndvi)\n",
        "            mean_ndvi = np.zeros((t,), dtype=float)\n",
        "            if len(all_ndvi_x_cls) > 1:\n",
        "                mean_ndvi = np.mean(all_ndvi_x_cls, axis=0)\n",
        "            if len(all_ndvi_x_cls) == 1:\n",
        "                mean_ndvi = all_ndvi_x_cls[0]\n",
        "            mmax_ndvi = self.__max_filter1d_valid(mean_ndvi, 5)\n",
        "            output_ndvi[:, pts] = mmax_ndvi.reshape(t, 1)\n",
        "\n",
        "        return torch.from_numpy(output_ndvi).float()\n",
        "\n",
        "    def __max_filter1d_valid(self, a, w):\n",
        "        b = a.clip(min=0)\n",
        "        return maximum_filter1d(b, size=w)\n",
        "\n",
        "    def get_dates(self, path, n=None):\n",
        "        files = os.listdir(path)\n",
        "        dates = list()\n",
        "        for f in files:\n",
        "            f = f.split(\"_\")[0]\n",
        "            if len(f) == 8:\n",
        "                dates.append(f)\n",
        "\n",
        "        dates = set(dates)\n",
        "\n",
        "        if n is not None:\n",
        "            dates = random.sample(dates, n)\n",
        "\n",
        "        dates = list(dates)\n",
        "        dates.sort()\n",
        "        return dates\n",
        "\n",
        "    def print_stats(self, stats):\n",
        "        print_lst = list()\n",
        "        for k, v in stats.items():\n",
        "            print_lst.append(\"{}:{}\".format(k, v))\n",
        "        print('\\n', \", \".join(print_lst))\n",
        "\n",
        "def main():\n",
        "    root_path = '/content/sentinel2-munich480/munich480'\n",
        "    sample_duration = 30\n",
        "    batch_size = 4\n",
        "    workers = 2  # Reduce the number of workers as suggested by the warning\n",
        "\n",
        "    traindataset = SentinelDataset(root_path, tileids=\"tileids/train_fold0.tileids\", seqlength=sample_duration)\n",
        "    traindataloader = torch.utils.data.DataLoader(\n",
        "        traindataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "\n",
        "    # Load test set\n",
        "    testdataset = SentinelDataset(root_path, tileids=\"tileids/test_fold0.tileids\", seqlength=sample_duration)\n",
        "    testdataloader = torch.utils.data.DataLoader(\n",
        "        testdataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "\n",
        "    # Load validation set\n",
        "    validationdataset = SentinelDataset(root_path, tileids=\"tileids/eval.tileids\", seqlength=sample_duration)\n",
        "    validationdataloader = torch.utils.data.DataLoader(\n",
        "        validationdataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "\n",
        "    # Iterate through data loader to check if the errors are resolved\n",
        "    for iteration, data in enumerate(traindataloader):\n",
        "        input, target, target_ndvi, _, _ = data\n",
        "        print('input temporal series with 30 images of size 13x48x48:', input.shape)\n",
        "        print('target segmentation image (batchx48x48):', target.shape)\n",
        "        print('target_ndvi containing 30 channels of size 48x48:', target_ndvi.shape)\n",
        "        break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lXH3At9YPSX",
        "outputId": "fd8c3e1f-c11f-46ca-e145-cf06fee808c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1b28e670a30c>:4: DeprecationWarning: Please use `maximum_filter1d` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import maximum_filter1d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " rejected_nopath:3059, rejected_length:4778, total_samples:5231\n",
            "\n",
            " rejected_nopath:890, rejected_length:1395, total_samples:1747\n",
            "\n",
            " rejected_nopath:806, rejected_length:1441, total_samples:1641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1b28e670a30c>:233: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  dates = random.sample(dates, n)\n",
            "<ipython-input-5-1b28e670a30c>:233: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  dates = random.sample(dates, n)\n",
            "<ipython-input-5-1b28e670a30c>:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  new = np.zeros(label.shape, np.int)\n",
            "<ipython-input-5-1b28e670a30c>:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  new = np.zeros(label.shape, np.int)\n",
            "<ipython-input-5-1b28e670a30c>:195: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output_ndvi = np.zeros((t, h, w), dtype=np.float)\n",
            "<ipython-input-5-1b28e670a30c>:195: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output_ndvi = np.zeros((t, h, w), dtype=np.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input temporal series with 30 images of size 13x48x48: torch.Size([4, 13, 30, 48, 48])\n",
            "target segmentation image (batchx48x48): torch.Size([4, 48, 48])\n",
            "target_ndvi containing 30 channels of size 48x48: torch.Size([4, 30, 48, 48])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd\n",
        "\n",
        "try:\n",
        "    from visdom import Visdom\n",
        "except:\n",
        "    print(\"could not find visdom package. try 'pip install visdom'. continue without...\")\n",
        "    Visdom=None\n",
        "    pass\n",
        "\n",
        "class Printer():\n",
        "\n",
        "    def __init__(self, batchsize = None, N = None):\n",
        "        self.batchsize = batchsize\n",
        "        self.N = N\n",
        "\n",
        "        self.last=datetime.datetime.now()\n",
        "\n",
        "    def print(self, stats, iteration):\n",
        "        print_lst = list()\n",
        "\n",
        "        if self.N is None:\n",
        "            print_lst.append('iteration: {}'.format(iteration))\n",
        "        else:\n",
        "            print_lst.append('iteration: {}/{}'.format(iteration, self.N))\n",
        "\n",
        "        dt = (datetime.datetime.now() - self.last).total_seconds()\n",
        "\n",
        "        print_lst.append('logs/sec: {:.2f}'.format(dt / 1))\n",
        "\n",
        "        if self.batchsize is not None:\n",
        "            print_lst.append('samples/sec: {:.2f}'.format(dt / self.batchsize))\n",
        "\n",
        "        for k, v in zip(stats.keys(), stats.values()):\n",
        "            print_lst.append('{}: {:.2f}'.format(k, v))\n",
        "\n",
        "        print('\\r' + ', '.join(print_lst), end=\"\")\n",
        "\n",
        "        self.last = datetime.datetime.now()\n",
        "\n",
        "\n",
        "class Logger():\n",
        "\n",
        "    def __init__(self, columns, modes, csv=None, epoch=0, idx=0):\n",
        "\n",
        "        self.columns=columns\n",
        "        self.mode=modes[0]\n",
        "        self.epoch=epoch\n",
        "        self.idx = idx\n",
        "        self.data = pd.DataFrame(columns=[\"epoch\",\"iteration\",\"mode\"]+self.columns)\n",
        "        self.csv = csv\n",
        "\n",
        "    def resume(self, data):\n",
        "        self.data = data\n",
        "        self.idx = data.index[-1]\n",
        "        self.epoch = data[\"epoch\"].max()\n",
        "\n",
        "    def update_epoch(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            self.epoch+=1\n",
        "        else:\n",
        "            self.epoch=epoch\n",
        "\n",
        "    def set_mode(self,mode):\n",
        "        self.mode = mode\n",
        "\n",
        "    def log(self, stats, iteration):\n",
        "\n",
        "        stats[\"epoch\"] = self.epoch\n",
        "        stats[\"iteration\"] = iteration\n",
        "        stats[\"mode\"] = self.mode\n",
        "\n",
        "        row = pd.DataFrame(stats, index=[self.idx])\n",
        "\n",
        "        self.data = self.data.append(row, sort=False)\n",
        "        self.idx +=1\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data\n",
        "\n",
        "    def save_csv(self, path=None):\n",
        "        if path is not None:\n",
        "            self.data.to_csv(path)\n",
        "        elif self.csv is not None:\n",
        "            self.data.to_csv(self.csv)\n",
        "        else:\n",
        "            raise ValueError(\"please provide either path argument or initialize Logger() with csv argument\")\n",
        "\n",
        "class VisdomLogger():\n",
        "    def __init__(self,**kwargs):\n",
        "        if Visdom is None:\n",
        "            self.viz = None # do nothing\n",
        "            return\n",
        "\n",
        "        self.viz = Visdom(**kwargs)\n",
        "        self.windows = dict()\n",
        "\n",
        "        r = np.random.RandomState(1)\n",
        "        self.colors = r.randint(0,255, size=(255,3))\n",
        "        self.colors[0] = np.array([1., 1., 1.])\n",
        "        self.colors[1] = np.array([0. , 0.18431373, 0.65490196]) # ikb blue\n",
        "\n",
        "    def update(self, data):\n",
        "        self.plot_epochs(data)\n",
        "        self.plot_steps(data)\n",
        "\n",
        "    def plot_steps(self, data, maxplotpoints=50):\n",
        "\n",
        "        if not self.viz.check_connection():\n",
        "            return # do nothing\n",
        "\n",
        "        name=\"loss\"\n",
        "        win = \"c_\"+name\n",
        "        if \"c_\"+name in self.windows.keys():\n",
        "            #win = self.windows[\"c_\"+name]\n",
        "            update = 'new'\n",
        "        else:\n",
        "            #win = None  # first log -> new window\n",
        "            update = None\n",
        "\n",
        "        for mode in data[\"mode\"].unique():\n",
        "            d = data.loc[data[\"mode\"] == mode]\n",
        "\n",
        "            maxiter = d[\"iteration\"].max()\n",
        "\n",
        "            if len(d) > maxplotpoints:\n",
        "                d = d.tail(maxplotpoints)\n",
        "                #d = d.sample(maxplotpoints).sort_index()\n",
        "\n",
        "            if maxiter > 0:\n",
        "                frac_epochs = d[\"epoch\"] + d[\"iteration\"] / maxiter\n",
        "            else:\n",
        "                frac_epochs = np.array([0])\n",
        "            #total_iter = d[\"epoch\"]*maxiter + d[\"iteration\"]\n",
        "            values = d[name]\n",
        "\n",
        "            opts = dict(\n",
        "                title=name,\n",
        "                showlegend=True,\n",
        "                xlabel='epochs',\n",
        "                ylabel=name)\n",
        "\n",
        "            win = self.viz.line(\n",
        "                X=frac_epochs,\n",
        "                Y=values,\n",
        "                name=mode,\n",
        "                win=win,\n",
        "                opts=opts,\n",
        "                update=update\n",
        "            )\n",
        "            update = 'insert'\n",
        "\n",
        "        self.windows[\"c_\"+name] = win\n",
        "\n",
        "    def plot_epochs(self, data):\n",
        "        \"\"\"\n",
        "        Plots mean of epochs\n",
        "\n",
        "        :param data:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if self.viz is None:\n",
        "            return # do nothing\n",
        "\n",
        "        if not self.viz.check_connection():\n",
        "            return # do nothing\n",
        "\n",
        "        data_mean_per_epoch = data.groupby([\"mode\", \"epoch\"]).mean()\n",
        "        cols = data_mean_per_epoch.columns\n",
        "        modes = data_mean_per_epoch.index.levels[0]\n",
        "\n",
        "        for name in cols:\n",
        "\n",
        "             if name in self.windows.keys():\n",
        "                 win = self.windows[name]\n",
        "                 update = 'new'\n",
        "             else:\n",
        "                 win = name # first log -> new window\n",
        "                 update = None\n",
        "\n",
        "             opts = dict(\n",
        "                 title=name,\n",
        "                 showlegend=True,\n",
        "                 xlabel='epochs',\n",
        "                 ylabel=name)\n",
        "\n",
        "             for mode in modes:\n",
        "\n",
        "                 epochs = data_mean_per_epoch[name].loc[mode].index\n",
        "                 values = data_mean_per_epoch[name].loc[mode]\n",
        "\n",
        "                 win = self.viz.line(\n",
        "                     X=epochs,\n",
        "                     Y=values,\n",
        "                     name=mode,\n",
        "                     win=win,\n",
        "                     opts=opts,\n",
        "                     update=update\n",
        "                 )\n",
        "                 update='insert'\n",
        "\n",
        "             self.windows[name] = win\n",
        "\n",
        "\n",
        "    def plot_images(self, target, output):\n",
        "        if self.viz is None:\n",
        "            return\n",
        "\n",
        "        if not self.viz.check_connection():\n",
        "            return # do nothing\n",
        "\n",
        "\n",
        "        # log softmax -> softmax\n",
        "        output = np.exp(output)\n",
        "\n",
        "        prediction = np.argmax(output, axis=1)\n",
        "\n",
        "        target = np.swapaxes(self.colors[target], -1, 1)\n",
        "        prediction = np.swapaxes(self.colors[prediction], -1, 1)\n",
        "\n",
        "        self.viz.images(target, win=\"target\", opts=dict(title='Target'))\n",
        "        self.viz.images(prediction, win=\"predictions\", opts=dict(title='Predictions'))\n",
        "\n",
        "        b, c, h, w = output.shape\n",
        "        for cl in range(c):\n",
        "            arr = np.expand_dims(output[:,cl],1)*255\n",
        "            self.viz.images(arr, win=\"class\"+str(cl), opts=dict(title=\"class\"+str(cl)))"
      ],
      "metadata": {
        "id": "1rT5C0J-udYu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import re\n",
        "\n",
        "class ProgressBar(object):\n",
        "    DEFAULT = 'Progress: %(bar)s %(percent)3d%%'\n",
        "    FULL = '%(bar)s %(current)d/%(total)d (%(percent)3d%%) %(remaining)d to go'\n",
        "\n",
        "    def __init__(self, total, width=40, fmt=DEFAULT, symbol='=',\n",
        "                 output=sys.stderr):\n",
        "        assert len(symbol) == 1\n",
        "\n",
        "        self.total = total\n",
        "        self.width = width\n",
        "        self.symbol = symbol\n",
        "        self.output = output\n",
        "        self.fmt = re.sub(r'(?P<name>%\\(.+?\\))d',\n",
        "            r'\\g<name>%dd' % len(str(total)), fmt)\n",
        "\n",
        "        self.current = 0\n",
        "\n",
        "    def __call__(self):\n",
        "        percent = self.current / float(self.total)\n",
        "        size = int(self.width * percent)\n",
        "        remaining = self.total - self.current\n",
        "        bar = '[' + self.symbol * size + ' ' * (self.width - size) + ']'\n",
        "\n",
        "        args = {\n",
        "            'total': self.total,\n",
        "            'bar': bar,\n",
        "            'current': self.current,\n",
        "            'percent': percent * 100,\n",
        "            'remaining': remaining\n",
        "        }\n",
        "        print('\\r' + self.fmt % args, file=self.output, end='')\n",
        "\n",
        "    def done(self):\n",
        "        self.current = self.total\n",
        "        self()\n",
        "        print('', file=self.output)"
      ],
      "metadata": {
        "id": "84gvWK1HuxLZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def save(path, model, optimizer, **kwargs):\n",
        "    model_state = None\n",
        "    optimizer_state = None\n",
        "    if model is not None:\n",
        "        model_state = model.state_dict()\n",
        "    if optimizer is not None:\n",
        "        optimizer_state = optimizer.state_dict()\n",
        "    torch.save(\n",
        "        dict(model_state=model_state,\n",
        "             optimizer_state=optimizer_state,\n",
        "             **kwargs),\n",
        "        path\n",
        "    )\n",
        "\n",
        "\n",
        "def resume(path, model, optimizer):\n",
        "    if torch.cuda.is_available():\n",
        "        snapshot = torch.load(path)\n",
        "    else:\n",
        "        snapshot = torch.load(path, map_location=\"cpu\")\n",
        "\n",
        "    model_state = snapshot.pop('model_state', snapshot)\n",
        "    optimizer_state = snapshot.pop('optimizer_state', None)\n",
        "\n",
        "    if model is not None and model_state is not None:\n",
        "        print(\"load model\")\n",
        "        model.load_state_dict(model_state)\n",
        "\n",
        "    if optimizer is not None and optimizer_state is not None:\n",
        "        optimizer.load_state_dict(optimizer_state)\n",
        "    return snapshot"
      ],
      "metadata": {
        "id": "FEUjZA5ZuxlG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "\n",
        "\n",
        "class ConvLSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "\n",
        "        self.height, self.width = input_size\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
        "        self.bias        = bias\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
        "                              out_channels=4 * self.hidden_dim,\n",
        "                              kernel_size=self.kernel_size,\n",
        "                              padding=self.padding,\n",
        "                              bias=self.bias)\n",
        "\n",
        "    def forward(self, input_tensor, cur_state):\n",
        "        h_cur, c_cur = cur_state\n",
        "\n",
        "        # Ensure that h_cur and c_cur are on the same device as input_tensor\n",
        "        h_cur = h_cur.to(input_tensor.device)\n",
        "        c_cur = c_cur.to(input_tensor.device)\n",
        "\n",
        "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
        "\n",
        "        combined_conv = self.conv(combined)\n",
        "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
        "        i = torch.sigmoid(cc_i)\n",
        "        f = torch.sigmoid(cc_f)\n",
        "        o = torch.sigmoid(cc_o)\n",
        "        g = torch.tanh(cc_g)\n",
        "\n",
        "        c_next = f * c_cur + i * g\n",
        "        h_next = o * torch.tanh(c_next)\n",
        "\n",
        "        return h_next, c_next\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size, input_tensor):\n",
        "      return (torch.zeros(batch_size, self.hidden_dim, self.height, self.width, device=input_tensor.device),\n",
        "            torch.zeros(batch_size, self.hidden_dim, self.height, self.width, device=input_tensor.device))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ConvLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
        "                 batch_first=False, bias=True, return_all_layers=False):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "\n",
        "        self._check_kernel_size_consistency(kernel_size)\n",
        "\n",
        "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
        "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
        "        hidden_dim  = self._extend_for_multilayer(hidden_dim, num_layers)\n",
        "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
        "            raise ValueError('Inconsistent list length.')\n",
        "\n",
        "        self.height, self.width = input_size\n",
        "\n",
        "        self.input_dim  = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.kernel_size = kernel_size\n",
        "        self.num_layers = num_layers\n",
        "        self.batch_first = batch_first\n",
        "        self.bias = bias\n",
        "        self.return_all_layers = return_all_layers\n",
        "\n",
        "        cell_list = []\n",
        "        for i in range(0, self.num_layers):\n",
        "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i-1]\n",
        "\n",
        "            cell_list.append(ConvLSTMCell(input_size=(self.height, self.width),\n",
        "                                          input_dim=cur_input_dim,\n",
        "                                          hidden_dim=self.hidden_dim[i],\n",
        "                                          kernel_size=self.kernel_size[i],\n",
        "                                          bias=self.bias))\n",
        "\n",
        "        self.cell_list = nn.ModuleList(cell_list)\n",
        "\n",
        "    def forward(self, input_tensor, hidden_state=None):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        input_tensor: todo\n",
        "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
        "        hidden_state: todo\n",
        "            None. todo implement stateful\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        last_state_list, layer_output\n",
        "        \"\"\"\n",
        "        if not self.batch_first:\n",
        "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
        "            input_tensor.permute(1, 0, 2, 3, 4)\n",
        "\n",
        "        # Implement stateful ConvLSTM\n",
        "        if hidden_state is not None:\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            hidden_state = self._init_hidden(batch_size=input_tensor.size(0))\n",
        "\n",
        "        layer_output_list = []\n",
        "        last_state_list   = []\n",
        "\n",
        "        seq_len = input_tensor.size(1)\n",
        "        cur_layer_input = input_tensor\n",
        "\n",
        "        for layer_idx in range(self.num_layers):\n",
        "\n",
        "            h, c = hidden_state[layer_idx]\n",
        "            output_inner = []\n",
        "            for t in range(seq_len):\n",
        "\n",
        "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
        "                                                 cur_state=[h, c])\n",
        "                output_inner.append(h)\n",
        "\n",
        "            layer_output = torch.stack(output_inner, dim=1)\n",
        "            cur_layer_input = layer_output\n",
        "\n",
        "            layer_output_list.append(layer_output)\n",
        "            last_state_list.append([h, c])\n",
        "\n",
        "        if not self.return_all_layers:\n",
        "            layer_output_list = layer_output_list[-1:]\n",
        "            last_state_list   = last_state_list[-1:]\n",
        "\n",
        "        return layer_output_list, last_state_list\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_layers):\n",
        "            init_states.append(self.cell_list[i].init_hidden(batch_size))\n",
        "        return init_states\n",
        "\n",
        "    @staticmethod\n",
        "    def _check_kernel_size_consistency(kernel_size):\n",
        "        if not (isinstance(kernel_size, tuple) or\n",
        "                    (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
        "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
        "\n",
        "    @staticmethod\n",
        "    def _extend_for_multilayer(param, num_layers):\n",
        "        if not isinstance(param, list):\n",
        "            param = [param] * num_layers\n",
        "        return param"
      ],
      "metadata": {
        "id": "zq9Ldnclu_vv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "# from models.convlstm.convlstm import ConvLSTMCell\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LSTMSequentialEncoder(torch.nn.Module):\n",
        "    def __init__(self, height, width, input_dim=30, hidden_dim=64, nclasses=8, kernel_size=(3,3), bias=False):\n",
        "        super(LSTMSequentialEncoder, self).__init__()\n",
        "\n",
        "        self.inconv = torch.nn.Conv3d(input_dim, hidden_dim, (1, 3, 3))\n",
        "        self.conv1 = nn.Conv2d(13, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.cell = ConvLSTMCell(input_size=(height, width),\n",
        "                                 input_dim=hidden_dim,\n",
        "                                 hidden_dim=hidden_dim,\n",
        "                                 kernel_size=kernel_size,\n",
        "                                 bias=bias)\n",
        "\n",
        "        # Modify the final layer to produce class probabilities\n",
        "        self.final = torch.nn.Sequential(\n",
        "            torch.nn.AdaptiveAvgPool2d(1),  # Global average pooling\n",
        "            torch.nn.Flatten(),\n",
        "            torch.nn.Linear(hidden_dim, nclasses),\n",
        "            torch.nn.Softmax(dim=1)  # Apply softmax activation\n",
        "        )\n",
        "\n",
        "    def forward(self, x, hidden=None, state=None):\n",
        "\n",
        "        # (b x t x c x h x w) -> (b x c x t x h x w)\n",
        "        x = x.permute(0,2,1,3,4)\n",
        "\n",
        "        x = torch.nn.functional.pad(x, (1, 1, 1, 1), 'constant', 0)\n",
        "        x = self.inconv.forward(x)\n",
        "\n",
        "        b, c, t, h, w = x.shape\n",
        "\n",
        "        if hidden is None:\n",
        "            hidden = torch.zeros((b, c, h, w))\n",
        "        if state is None:\n",
        "            state = torch.zeros((b, c, h, w))\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            hidden = hidden.cuda()\n",
        "            state = state.cuda()\n",
        "\n",
        "        for iter in range(t):\n",
        "\n",
        "            hidden, state = self.cell.forward(x[:,:,iter,:,:], (hidden, state))\n",
        "\n",
        "        x = torch.nn.functional.pad(state, (1, 1, 1, 1), 'constant', 0)\n",
        "        x = self.final.forward(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "\n",
        "\n",
        "    b, t, c, h, w = 2, 10, 3, 320, 320\n",
        "\n",
        "    model = LSTMSequentialEncoder(height=h, width=w, input_dim=c, hidden_dim=3)\n",
        "\n",
        "    x = torch.randn((b, t, c, h, w))\n",
        "\n",
        "\n",
        "    hidden, state = model.forward(x)"
      ],
      "metadata": {
        "id": "FRl5nhXiu2kS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create an instance of the model\n",
        "model = LSTMSequentialEncoder(height=320, width=320, input_dim=30, hidden_dim=64, nclasses=8)\n",
        "\n",
        "# Generate sample input data\n",
        "batch_size = 2\n",
        "seq_length = 10\n",
        "input_channels = 30\n",
        "height = 320\n",
        "width = 320\n",
        "sample_input = torch.randn((batch_size, seq_length, input_channels, height, width))\n",
        "\n",
        "# Pass the input data through the model\n",
        "hidden, state = model.forward(sample_input)\n",
        "\n",
        "# Examine the output\n",
        "print(\"Model output shape:\", hidden.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Y6nkSJxr_Z",
        "outputId": "b4c7a546-d9d6-44f1-a14b-f2e576c68b16"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output shape: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define your data transformations\n",
        "data_transforms = transforms.Compose([\n",
        "\n",
        "])\n",
        "\n",
        "data_dir = \"/content/sentinel2-munich480/munich480\"\n",
        "# Define your custom dataset\n",
        "train_dataset = SentinelDataset(data_dir, tileids=\"tileids/train_fold0.tileids\")\n",
        "test_dataset = SentinelDataset(data_dir, tileids=\"tileids/test_fold0.tileids\")\n",
        "\n",
        "# Create a custom dataset wrapper to apply transformations\n",
        "class TransformedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x, y = self.dataset[index]\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "# Apply transformations to the datasets\n",
        "train_dataset = TransformedDataset(train_dataset, transform=data_transforms)\n",
        "test_dataset = TransformedDataset(test_dataset, transform=data_transforms)\n",
        "workers=4\n",
        "# Create data loaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJnaRIok1A47",
        "outputId": "653bedf2-3e16-4ad8-942e-57fb25bcb024"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " rejected_nopath:3059, rejected_length:4778, total_samples:5231\n",
            "\n",
            " rejected_nopath:890, rejected_length:1395, total_samples:1747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import os\n",
        "import time\n",
        "import visdom\n",
        "\n",
        "# Define your dataset directory (modify this)\n",
        "data_dir = \"/content/sentinel2-munich480/munich480\"\n",
        "\n",
        "# Define hyperparameters and variables\n",
        "batch_size = 16\n",
        "num_workers = 0\n",
        "epochs = 100\n",
        "learning_rate = 1e-3\n",
        "snapshot = None\n",
        "checkpoint_dir = None\n",
        "\n",
        "# Create a logger\n",
        "logger = Logger(columns=[\"loss\"], modes=[\"train\", \"test\"])\n",
        "vizlogger = VisdomLogger()\n",
        "\n",
        "# Create your model\n",
        "nclasses = len(train_dataset.classes)\n",
        "network = LSTMSequentialEncoder(48, 48, nclasses=nclasses)\n",
        "\n",
        "# Define your optimizer and loss function\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
        "loss = torch.nn.NLLLoss()\n",
        "\n",
        "# Move the model and loss to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    network = torch.nn.DataParallel(network).cuda()\n",
        "    loss = loss.cuda()\n",
        "\n",
        "# Optionally, load weights from a snapshot\n",
        "if snapshot is not None:\n",
        "    state = torch.load(snapshot)\n",
        "\n",
        "    if \"epoch\" in state.keys():\n",
        "        start_epoch = state[\"epoch\"]\n",
        "\n",
        "    if \"data\" in state.keys():\n",
        "        logger.resume(state[\"data\"])\n",
        "\n",
        "# Define train_epoch and test_epoch functions here\n",
        "def train_epoch(dataloader, network, optimizer, loss, loggers):\n",
        "    logger, vizlogger = loggers\n",
        "\n",
        "    printer = Printer(N=len(dataloader))\n",
        "    logger.set_mode(\"train\")\n",
        "\n",
        "    for iteration, data in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, targets = data  # Unpack inputs and targets\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "        outputs = network(inputs)\n",
        "        l = loss(outputs, targets)\n",
        "        # print(l)\n",
        "        stats = {\"loss\": l.item()}  # Use item() to get a scalar value from the tensor\n",
        "\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        printer.print(stats, iteration)\n",
        "        logger.log(stats, iteration)\n",
        "        vizlogger.plot_steps(logger.get_data())\n",
        "\n",
        "def test_epoch(dataloader, network, loss, loggers):\n",
        "    logger, vizlogger = loggers\n",
        "    printer = Printer(N=len(dataloader))\n",
        "    logger.set_mode(\"test\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for iteration, data in enumerate(dataloader):\n",
        "            input, target = data\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                input = input.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "            output = network.forward(input)\n",
        "            l = loss(output, target)\n",
        "            stats = {\"loss\": l.data.cpu().numpy()}\n",
        "\n",
        "            printer.print(stats, iteration)\n",
        "            logger.log(stats, iteration)\n",
        "            vizlogger.plot_steps(logger.get_data())\n",
        "\n",
        "        vizlogger.plot_images(target.cpu().detach().numpy(), output.cpu().detach().numpy())\n",
        "\n",
        "# Start a Visdom server in the background\n",
        "!python -m visdom.server -port 8097 > /dev/null 2>&1 &\n",
        "\n",
        "# Wait for a few seconds to ensure the server has started\n",
        "time.sleep(5)\n",
        "\n",
        "# Initialize the Visdom client\n",
        "viz = visdom.Visdom(port=8097)\n",
        "\n",
        "# Define your custom dataset and data loaders\n",
        "train_dataset = SentinelDataset(data_dir, tileids=\"tileids/train_fold0.tileids\")\n",
        "test_dataset = SentinelDataset(data_dir, tileids=\"tileids/test_fold0.tileids\")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "start_epoch = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    logger.update_epoch(epoch)\n",
        "\n",
        "    print(\"\\nEpoch {}\".format(epoch))\n",
        "    print(\"train\")\n",
        "    train_epoch(train_dataloader, network, optimizer, loss, loggers=(logger, vizlogger))\n",
        "    print(\"\\ntest\")\n",
        "    test_epoch(test_dataloader, network, loss, loggers=(logger, vizlogger))\n",
        "\n",
        "    data = logger.get_data()\n",
        "    vizlogger.update(data)\n",
        "\n",
        "    if checkpoint_dir is not None:\n",
        "        checkpoint_name = os.path.join(checkpoint_dir, \"model_{:02d}.pth\".format(epoch))\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": network.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"loss\": loss,\n",
        "                \"data\": data\n",
        "            },\n",
        "            checkpoint_name\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AGS-_5xk0F-q",
        "outputId": "c8da85c7-4e59-425c-b115-3366fab9bd83"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 790, in urlopen\n",
            "    response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 496, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n",
            "    self.sock = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7bc488830640>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 844, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bc488830640>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/visdom/__init__.py\", line 429, in _send\n",
            "    r = requests.post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 115, in post\n",
            "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bc488830640>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc488803250>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in user code:\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc48a419120>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc488803250>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc48a419120>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc488803250>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "WARNING:visdom:Visdom python client failed to establish socket to get messages from the server. This feature is optional and can be disabled by initializing Visdom with `use_incoming_socket=False`, which will prevent waiting for this request to timeout.\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc48a419120>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc488803250>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n",
            "    sock = connection.create_connection(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n",
            "    raise err\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n",
            "    sock.connect(sa)\n",
            "ConnectionRefusedError: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 790, in urlopen\n",
            "    response = self._make_request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 496, in _make_request\n",
            "    conn.request(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n",
            "    self.endheaders()\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n",
            "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n",
            "    self.send(msg)\n",
            "  File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n",
            "    self.connect()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n",
            "    self.sock = self._new_conn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n",
            "    raise NewConnectionError(\n",
            "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7bc4a946f2b0>: Failed to establish a new connection: [Errno 111] Connection refused\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n",
            "    resp = conn.urlopen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 844, in urlopen\n",
            "    retries = retries.increment(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n",
            "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
            "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bc4a946f2b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/visdom/__init__.py\", line 429, in _send\n",
            "    r = requests.post(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 115, in post\n",
            "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n",
            "    raise ConnectionError(e, request=request)\n",
            "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bc4a946f2b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc48a3ea4d0>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in user code:\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc48a419120>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n",
            "ERROR:visdom:[Errno 99] Cannot assign requested address\n",
            "ERROR:websocket:[Errno 99] Cannot assign requested address - goodbye\n",
            "ERROR:websocket:error from callback <function Visdom.setup_socket.<locals>.on_close at 0x7bc488803250>: Visdom.setup_socket.<locals>.on_close() takes 1 positional argument but 3 were given\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " rejected_nopath:3059, rejected_length:4778, total_samples:5231\n",
            "\n",
            " rejected_nopath:890, rejected_length:1395, total_samples:1747\n",
            "\n",
            "Epoch 0\n",
            "train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-1b28e670a30c>:233: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  dates = random.sample(dates, n)\n",
            "<ipython-input-5-1b28e670a30c>:158: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  new = np.zeros(label.shape, np.int)\n",
            "<ipython-input-5-1b28e670a30c>:195: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  output_ndvi = np.zeros((t, h, w), dtype=np.float)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-54d58bc608b2>\u001b[0m in \u001b[0;36m<cell line: 118>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEpoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloggers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvizlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\ntest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloggers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvizlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-54d58bc608b2>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, network, optimizer, loss, loggers)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m  \u001b[0;31m# Unpack inputs and targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q33Kp8tJLkRh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}